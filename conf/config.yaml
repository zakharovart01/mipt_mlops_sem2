params:
  PATH: data/
  MODEL_PATH: model/
  MAX_LEN: 128
  BATCH_SIZE: 2
  HUG_FACE: cointegrated/rubert-tiny2
  SEED: 42

label: label

data:
  csv_path: /home/artemy/Рабочий стол/proj/mipt_mlops_sem2/data/train.csv
  val_size: 0.2
  dataloader_num_wokers: 2
  batch_size: 2
  text_max_length: 128

model:
  name: cointegrated/rubert-tiny2
  dropout: 0.5
  freeze_backbone: false

trainer:
  lr: 3e-4
  n_epochs: 2
  weight_decay: 1e-6

test_params:
    batch_size: ${params.BATCH_SIZE}
    shuffle: False
    num_workers: 0

train_params:
    batch_size: ${params.BATCH_SIZE}
    shuffle: True
    num_workers: 0

train:
  learning_rate: 2e-5
  weight_decay: 0.01
  num_warmup_steps: 1
  num_training_steps: 10
  grad_accum_steps: 4
  # accelerator: cuda
  # devices:
  #   - 0
  accelerator: cpu
  devices: 1
  precision: 16-mixed
  val_check_interval: 1.0
  overfit_batches: 0
  num_sanity_val_steps: 4
  full_deterministic_mode: false
  benchmark: false
  gradient_clip_val: 1.0
  profiler:
  log_every_n_steps: 1
  batch_size_finder: false
  detect_anomaly: false

artifacts:
  experiment_name: example-experiment
  checkpoint:
    use: false
    dirpath: checkpoints
    filename: "{epoch:02d}-{val_loss:.4f}"
    monitor: val_loss
    save_top_k: 3
    every_n_train_steps:
    every_n_epochs: 1

callbacks:
  model_summary:
    max_depth: 1
  swa:
    use: false
    lrs: 1e-3
